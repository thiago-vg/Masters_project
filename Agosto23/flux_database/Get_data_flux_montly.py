# -*- coding: utf-8 -*-
"""
Created on Fri Aug 11 13:55:49 2023

@author: thiag
"""


"""GOES-16 products processing

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tF-GMOUDRPZeFwslQd0fOeL_H1Jtu5mM

Fire product: 

OR_ABI-L2-FDCF-M3_G16_sYYYYJJJHHMMSSs_eYYYYJJJHHMMSSs_cYYYYJJJHHMMSSs.nc
"""

###############################################################################
# Define input and output folders and file
import os
from io import BytesIO
import s3fs
import xarray as xr
# import cartopy.crs as ccrs
import numpy as np
import glob
from pyproj import Proj
import pandas as pd
import warnings
import calendar
# import time

def get_matrix_lat_lon_feer(minlon,maxlon,minlat,maxlat,dados_feer):
    
    centers_lon = np.linspace(minlon+0.5, maxlon-0.5,num=int(maxlon-minlon))
    centers_lat = np.linspace(minlat+0.5, maxlat-0.5,num=int(maxlat-minlat))
        
    # centers_lon = np.linspace(minlon, maxlon,num=int(maxlon-minlon)+1)
    # print(centers_lon)
    # centers_lat = np.linspace(minlat, maxlat,num=int(maxlat-minlat)+1)
    # print(centers_lat)
    aux_list = []
    
    for i in range(0,len(centers_lat)):
        df2 = dados_feer.loc[(dados_feer['Latitude'] == centers_lat[i]) & (dados_feer['Longitude'] <= maxlon )
                           & (dados_feer['Longitude'] >= minlon ),'Ce_850'].to_numpy()
        aux_list = np.append(aux_list,df2)
        if i == 0:
            aux = np.repeat(centers_lat[i],len(centers_lon))
            lat_lon_feer = np.column_stack((aux,centers_lon))
            # latlon = np.vstack((latlon,au2))
        else:
            # print(i)
            aux = np.repeat(centers_lat[i],len(centers_lon))
            aux2 = np.column_stack((aux,centers_lon))
            lat_lon_feer = np.vstack((lat_lon_feer,aux2))
    # print(lat_lon_feer)
    lat_lon_feer = np.column_stack((lat_lon_feer,aux_list))   
    return lat_lon_feer

###############################################################################
# Initialize geometric variables
def get_lat_lon(file_system):
    files = file_system.ls('noaa-goes16/ABI-L2-FDCF/2021/'+str(200).zfill(3)+'/'+str(15).zfill(2)+'/') # list of 6 files for 2021 day 200, UTC time 15:00, 15:10, 15:20, ..., 15:50

    with fs.open(files[0], 'rb') as f:
      ds0 = xr.open_dataset(BytesIO(f.read()), engine='h5netcdf')

    # sat_h = ds0.goes_imager_projection.perspective_point_height[0] # ubuntu old version
    # sat_lon = ds0.goes_imager_projection.longitude_of_projection_origin[0] # ubuntu old version
    # sat_sweep = ds0.goes_imager_projection.sweep_angle_axis[0] # ubuntu old version
    sat_h = ds0.goes_imager_projection.perspective_point_height # Windows version
    sat_lon = ds0.goes_imager_projection.longitude_of_projection_origin # Windows version
    sat_sweep = ds0.goes_imager_projection.sweep_angle_axis # Windows version
    # oproj=ccrs.Geostationary(central_longitude=sat_lon,satellite_height=sat_h,sweep_axis=sat_sweep)
    p = Proj(proj='geos', h=sat_h, lon_0=sat_lon, sweep=sat_sweep)
    X = np.array(ds0.x) * sat_h
    Y = np.array(ds0.y) * sat_h
    XX, YY = np.meshgrid(X,Y)
    rlon, rlat = p(XX, YY, inverse=True)
    
    return rlat,rlon
# CIMSS product
def get_files(s_year,e_year,s_day,e_day,s_hour,e_our):
    print('Getting file names')
    aux = []
    for y in range(s_year,e_year+1):
        for d in range(s_day,e_day):
            #The range of the variable 'd' will determine the days of the product
            for j in range(s_hour,e_our):
                FD = fs.ls('noaa-goes16/ABI-L2-FDCF/'+str(y)+'/'+str(d).zfill(3)+'/'+str(j).zfill(2)+'/') # list of 6 files for 2020 day 228, UTC time 15:00, 15:10, 15:20, ..., 15:50
                #prodbase='OR_ABI-L2-FDCF-M6_G16_s' #Product code 'OR_ABI-L2-FDCF-M6_G16_s'
                #Difference btw M4 and M6 product?????
                #print("Hello {} {}, hope you're well!".format(first_name,last_name))
                # print('noaa-goes16/ABI-L2-FDCF/2020/'+str(d).zfill(3)+'/'+str(j).zfill(2)+'/')
                # print('Processing day {}, hour: {}'.format(d,str(j).zfill(2))) #Processing Message    
                # print(type(FD))
                # print(np.shape(FD))
                # print(len(FD))
                # print(FD)
                # print(FD[1])
                aux = np.append(aux,FD)
    return aux

def get_indexes(min_lon,max_lon,min_lat,max_lat,rlat,rlon,matrix):
    I = np.where((rlat>=min_lat)&(rlat<=max_lat)&(rlon>=min_lon)&(rlon<=max_lon))
    index_list = []
    index_list.insert(0,I)
    # print(index_list)
    for k in range(0,len(matrix)):
        aux1=np.where((rlat>=matrix[k,0]-0.5)&(rlat<=matrix[k,0]+0.5)&(rlon>=matrix[k,1]-0.5)&(rlon<=matrix[k,1]+0.5))
        index_list.insert(k+1,aux1)
    # print(index_list)
    # print(len(index_list))
    # print(index_list[1])
    return index_list

def get_indexes_v2(min_lon,max_lon,min_lat,max_lat,rlat,rlon):
    centers_lon = np.linspace(minlon+0.25, maxlon-0.25,num=int(maxlon-minlon)*2)
    centers_lat = np.linspace(minlat+0.25, maxlat-0.25,num=int(maxlat-minlat)*2)
    
    
    
    print(centers_lon)
    print(centers_lat)
    
    for i in range(0,len(centers_lat)):
        # df2 = dados_feer.loc[(dados_feer['Latitude'] == centers_lat[i]) & (dados_feer['Longitude'] <= maxlon )
        #                    & (dados_feer['Longitude'] >= minlon ),'Ce_850'].to_numpy()
        # aux_list = np.append(aux_list,df2)
        if i == 0:
            aux = np.repeat(centers_lat[i],len(centers_lon))
            lat_lon_feer = np.column_stack((aux,centers_lon))
            # latlon = np.vstack((latlon,au2))
        else:
            # print(i)
            aux = np.repeat(centers_lat[i],len(centers_lon))
            aux2 = np.column_stack((aux,centers_lon))
            lat_lon_feer = np.vstack((lat_lon_feer,aux2))
    print(lat_lon_feer)
    matrix = lat_lon_feer
    # lat_lon_feer = np.column_stack((lat_lon_feer,aux_list))   
    
    I = np.where((rlat>=min_lat)&(rlat<=max_lat)&(rlon>=min_lon)&(rlon<=max_lon))
    index_list = []
    index_list.insert(0,I)
    print(index_list)
    for k in range(0,len(matrix)):
        aux1=np.where((rlat>=matrix[k,0]-0.25)&(rlat<=matrix[k,0]+0.25)&(rlon>=matrix[k,1]-0.25)&(rlon<=matrix[k,1]+0.25))
        index_list.insert(k+1,aux1)
    # print(index_list)
    # print(len(index_list))
    # print(index_list[1])
    return index_list,matrix

def get_indexes_v3(min_lon,max_lon,min_lat,max_lat,rlat,rlon,dados_feer):
    # minlon,maxlon,minlat,maxlat=-72,-48,-9,-6 #Amazon big box v2
    centers_lon = np.linspace(minlon+0.25, maxlon-0.25,num=int(maxlon-minlon)*2)
    centers_lat = np.linspace(minlat+0.25, maxlat-0.25,num=int(maxlat-minlat)*2)
    
    centers_lon2 = np.linspace(minlon+0.5, maxlon-0.5,num=int(maxlon-minlon))
    centers_lat2 = np.linspace(minlat+0.5, maxlat-0.5,num=int(maxlat-minlat))
    
    # print(centers_lon2)
    # print(centers_lat2)
    aux_list = []
    
    for i in range(0,len(centers_lat2)):
        # df2 = dados_feer.loc[(dados_feer['Latitude'] == centers_lat[i]) & (dados_feer['Longitude'] <= maxlon )
        #                     & (dados_feer['Longitude'] >= minlon ),'Ce_850'].to_numpy()
        df2 = dados_feer.loc[(dados_feer['Latitude'] == centers_lat2[i]) & (dados_feer['Longitude'] <= (maxlon) )
                            & (dados_feer['Longitude'] >= (minlon) ),'Ce_850'].to_numpy()
        aux_list = np.append(aux_list,df2)
        if i == 0:
            aux2 = np.repeat(centers_lat2[i],len(centers_lon2))
            lat_lon_feer2 = np.column_stack((aux2,centers_lon2))
            # latlon = np.vstack((latlon,au2))
        else:
            # print(i)
            aux2 = np.repeat(centers_lat2[i],len(centers_lon2))
            aux2 = np.column_stack((aux2,centers_lon2))
            lat_lon_feer2 = np.vstack((lat_lon_feer2,aux2))
    lat_lon_feer2 = np.column_stack((lat_lon_feer2,aux_list))
    # print(lat_lon_feer2)
    
    for i in range(0,len(centers_lat)):
        # df2 = dados_feer.loc[(dados_feer['Latitude'] == centers_lat[i]) & (dados_feer['Longitude'] <= maxlon )
        #                     & (dados_feer['Longitude'] >= minlon ),'Ce_850'].to_numpy()
        # df2 = dados_feer.loc[(dados_feer['Latitude'] == centers_lat2[i]) & (dados_feer['Longitude'] <= (maxlon-0.50) )
        #                     & (dados_feer['Longitude'] >= (minlon+0.50) ),'Ce_850'].to_numpy()
        # aux_list = np.append(aux_list,df2)
        if i == 0:
            aux = np.repeat(centers_lat[i],len(centers_lon))
            lat_lon_feer = np.column_stack((aux,centers_lon))
            # latlon = np.vstack((latlon,au2))
        else:
            # print(i)
            aux = np.repeat(centers_lat[i],len(centers_lon))
            aux2 = np.column_stack((aux,centers_lon))
            lat_lon_feer = np.vstack((lat_lon_feer,aux2))
    
    # for n in range(0,len(lat_lon_feer)):
    #     dft = dados_feer.loc[((dados_feer['Latitude'] == lat_lon_feer[i,0]-0.25)or(dados_feer['Latitude'] == lat_lon_feer[i,0]+0.25)) 
    #                          & ((dados_feer['Longitude'] == lat_lon_feer[i,1]-0.25 ) or (dados_feer['Longitude'] == lat_lon_feer[i,1]+0.25)),'Ce_850'].to_numpy()
    #     aux_list = np.append(aux_list,dft)
    #     print(aux_list)
    # positions = np.where(latlonfeer[:,0]==)
    teste = []
    for j in range(0, len(lat_lon_feer)):
        for n in range(0,len(lat_lon_feer2)):
            if((lat_lon_feer[j,0]==lat_lon_feer2[n,0]+0.25)or(lat_lon_feer[j,0]==lat_lon_feer2[n,0]-0.25)):
                if((lat_lon_feer[j,1]==lat_lon_feer2[n,1]+0.25)or(lat_lon_feer[j,1]==lat_lon_feer2[n,1]-0.25)):
                    teste = np.append(teste,lat_lon_feer2[n,2])
    # print(lat_lon_feer)
    # print(teste)
    # print(len(lat_lon_feer))
    # print(len(teste))
    # matrix = lat_lon_feer
    lat_lon_feer = np.column_stack((lat_lon_feer,teste))
    matrix = lat_lon_feer
    # print(matrix)
    
    I = np.where((rlat>=min_lat)&(rlat<=max_lat)&(rlon>=min_lon)&(rlon<=max_lon))
    index_list = []
    index_list.insert(0,I)
    # print(index_list)
    for k in range(0,len(matrix)):
        aux1=np.where((rlat>=matrix[k,0]-0.25)&(rlat<=matrix[k,0]+0.25)&(rlon>=matrix[k,1]-0.25)&(rlon<=matrix[k,1]+0.25))
        index_list.insert(k+1,aux1)
    # print(index_list)
    # print(len(index_list))
    # print(index_list[1])
    return index_list,matrix

def process_data_v7(rlat,rlon,files,matrix,indexes):

    for i in range(0,len(files)):
      with fs.open(files[i], 'rb') as f:
          
        ds = xr.open_dataset(BytesIO(f.read()), engine='h5netcdf')
        try:
            #####################################################################
            #Dates and times information of the Data
            #print(files[i].split('/')[5])
            #print(prodbase)
            prodbase = files[i].split('/')[5][:23]
            #print(prodbase)
            starttime=files[i].split(prodbase)[1].split('_')[0]
            #print(starttime)
            year,julian,hhmm=starttime[:4],starttime[4:7],starttime[7:11]
            # plottitle=year+','+julian+','+hhmm
            # fpart = starttime+','+plottitle
            print('Processing year: {}, day: {}, hour: {}'.format(year,julian,hhmm)) #Processing Message    
            # code = int(year) + (int(julian)+(int(hhmm)/100)/24+(int(hhmm) % 100)/60/24)/1000
            # code = int(year) + (int(julian)+(int(hhmm)/100)/24+(int(hhmm) % 100)/60/24)/365
            # code = int(julian)+(int(hhmm)/100)/24+(int(hhmm) % 100)/60/24
            #####################################################################
            #FRP Data
            P = np.array(ds.Power)
            # T = np.array(ds.Temp)
            A = np.array(ds.Area)
            P_box_amazon = P[indexes[1]]
            A_box_amazon = A[indexes[1]]
            # print('Len P_box:', len(P_box_amazon))
            # print('Shape P_box:', np.shape(P_box_amazon))
            # print('Len A_box:', len(A_box_amazon))
            # print('Shape A_box:', np.shape(A_box_amazon))
            
            P_A_box_amazon = P_box_amazon/A_box_amazon
            # array_P_box_amazon = P_box_amazon[~np.isnan(P_box_amazon)]
            array_F_box_amazon = P_A_box_amazon[~np.isnan(P_A_box_amazon)]
            
            
            # P_box_test = np.ma.masked_array(P,mask=~((rlat>=matrix[0,0]-0.5)&(rlat<=matrix[0,0]+0.5)&(rlon>=matrix[0,1]-0.5)&(rlon<=matrix[0,1]+0.5)))
            # array_P_box_amazon = P_box_test.compressed()[~np.isnan(P_box_test.compressed())]
            lat = matrix[0,0]
            lon = matrix[0,1]
            ###################################################################
            #Método 2 fluxo 
            with warnings.catch_warnings():
                warnings.simplefilter("ignore", category=RuntimeWarning)
                mean_flux = np.mean(array_F_box_amazon)
                RE_flux = np.mean(array_F_box_amazon*matrix[0,2])
                CO2_flux = np.mean(array_F_box_amazon*Ce_CO2*matrix[0,2])
                CO_flux = np.mean(array_F_box_amazon*Ce_CO*matrix[0,2])
                CH4_flux = np.mean(array_F_box_amazon*Ce_CH4*matrix[0,2])
            if np.isnan(mean_flux):
                mean_flux = 0
            if np.isnan(RE_flux):
                RE_flux = 0
            if np.isnan(CO2_flux):
                CO2_flux = 0
            if np.isnan(CO_flux):
                CO_flux = 0
            if np.isnan(CH4_flux):
                CH4_flux = 0


            array_lat = lat
            array_lon = lon
            
            array_mean_flux = mean_flux
            array_mean_TPM = RE_flux
            array_CO2_flux = CO2_flux
            array_CO_flux = CO_flux
            array_CH4_flux = CH4_flux
            
            for k in range(1,len(matrix)):
                # print(matrix[k,0])
        
                # caixa = (rlat>=matrix[k,0]-0.5)&(rlat<=matrix[k,0]+0.5)&(rlon>=matrix[k,1]-0.5)&(rlon<=matrix[k,1]+0.5)
                # C_caixa = np.invert(caixa).astype(int)
                P_box_amazon = P[indexes[k+1]]
                # array_P_box_amazon = P_box_amazon[~np.isnan(P_box_amazon)]
                
                A_box_amazon = A[indexes[k+1]]
                # print('Len P_box:', len(P_box_amazon))
                # print('Shape P_box:', np.shape(P_box_amazon))
                # print('Len A_box:', len(A_box_amazon))
                # print('Shape A_box:', np.shape(A_box_amazon))
                
                P_A_box_amazon = P_box_amazon/A_box_amazon
                # array_P_box_amazon = P_box_amazon[~np.isnan(P_box_amazon)]
                array_F_box_amazon = P_A_box_amazon[~np.isnan(P_A_box_amazon)]

                
                lat = matrix[k,0]
                lon = matrix[k,1]
                
                with warnings.catch_warnings():
                    warnings.simplefilter("ignore", category=RuntimeWarning)
                    mean_flux = np.mean(array_F_box_amazon)
                    RE_flux = np.mean(array_F_box_amazon*matrix[k,2])
                    CO2_flux = np.mean(array_F_box_amazon*Ce_CO2*matrix[k,2])
                    CO_flux = np.mean(array_F_box_amazon*Ce_CO*matrix[k,2])
                    CH4_flux = np.mean(array_F_box_amazon*Ce_CH4*matrix[k,2])
                if np.isnan(mean_flux):
                    mean_flux = 0
                if np.isnan(RE_flux):
                    RE_flux = 0
                if np.isnan(CO2_flux):
                    CO2_flux = 0
                if np.isnan(CO_flux):
                    CO_flux = 0
                if np.isnan(CH4_flux):
                    CH4_flux = 0
                    

                array_lat = np.append(array_lat,lat)
                array_lon = np.append(array_lon,lon)
                
                array_mean_flux = np.append(array_mean_flux,mean_flux)
                array_mean_TPM = np.append(array_mean_TPM,RE_flux)
                array_CO2_flux = np.append(array_CO2_flux,CO2_flux)
                array_CO_flux = np.append(array_CO_flux,CO_flux)
                array_CH4_flux = np.append(array_CH4_flux,CH4_flux)
                               
           

        except OSError as error:
             print(error)

    return array_lat,array_lon,array_mean_flux,array_mean_TPM,array_CO2_flux,\
        array_CO_flux,array_CH4_flux
###############################################################################


# Define input and output folders and file
datadir = 'C:/Users/thiag/OneDrive/Documentos/Projeto_Mestrado/Agosto23/flux_database/'
# datadir = '/home/thiagovg//Documentos/Projeto_Mestrado/Abril23/FRP_amazon/fire_dinamics_graphs/' # ubuntu old version
# datadir2 = '/home/thiagovg//Documentos/Projeto_Mestrado/Abril23'
datadir2 = 'C:/Users/thiag/OneDrive/Documentos/Projeto_Mestrado/Agosto23'

data = sorted(glob.glob(datadir2+'/FEER*.csv'))
feer_data = pd.read_csv(data[0])
# print(feer_data)

outdir  = datadir+'output/'
# outfile = outdir+'goes_results_box_emission_rate_test_cerrado_cluster_v7.csv'
outfile = outdir+'goes_data_emission_rate_amazon_definitive_box_flux_montly_test.csv'
###############################################################################

#Define constants

#Acording to Nguyen and Wooster the species emission can be obtained by
#Ce_species = (EF_species/EF_TMP)*Ce_TPM
# EF_CO2 = 1613 # +- 95 g/kg_burned this value is for Savanna and Grassland biome. Andreae, 2001
# s_EF_CO2 = 95
# EF_CO = 65 # +- 20 g/kg_burned this value is for Savanna and Grassland biome. Andreae, 2001
# s_EF_CO = 20
# EF_CH4 = 2.3 # +- 0.9 g/kg_burned this value is for Savanna and Grassland biome. Andreae, 2001
# s_EF_CH4 = 0.9
# EF_TPM = 8.3 # +- 3.2 g/kg_burned this value is for Savanna and Grassland biome. Andreae, 2001
# s_EF_TPM = 3.2

EF_CO2 = 1620 # +- 70 g/kg_burned this value is for Tropical forest biome. Andreae, 2019
s_EF_CO2 = 70
EF_CO = 104 # +- 39 g/kg_burned this value is for Tropical forest biome. Andreae, 2019
s_EF_CO = 39
EF_CH4 = 6.5 # +- 1.6 g/kg_burned this value is for Tropical forest biome. Andreae, 2019
s_EF_CH4 = 1.6
EF_TPM = 8.7 # +- 3.1 g/kg_burned this value is for Tropical forest biome. Andreae, 2019
s_EF_TPM = 3.1

Ce_CO2 = (EF_CO2/EF_TPM) #kg/MJ 
Ce_CO = (EF_CO/EF_TPM)#kg/MJ
Ce_CH4 = (EF_CH4/EF_TPM) #kg/MJ

sigma_Ce_CO2 = np.sqrt((s_EF_CO2/EF_TPM)**2+(EF_CO2*s_EF_TPM/(EF_TPM)**2)**2) 
sigma_Ce_CO = np.sqrt((s_EF_CO/EF_TPM)**2+(EF_CO*s_EF_TPM/(EF_TPM)**2)**2) 
sigma_Ce_CH4 = np.sqrt((s_EF_CH4/EF_TPM)**2+(EF_CH4*s_EF_TPM/(EF_TPM)**2)**2) 
###############################################################################
###############################################################################
# Define a ROI in degrees
#minlon,maxlon,minlat,maxlat=-80,-40,-30,5
#minlon,maxlon,minlat,maxlat=-61,-53,-20,-14
#minlon,maxlon,minlat,maxlat=-58,-56,-18,-16
# minlon,maxlon,minlat,maxlat=-57,-54,-9,-6 #Amazon small box
# minlon,maxlon,minlat,maxlat=-72.5,-48.5,-9.5,-5.5 #Amazon big box
minlon,maxlon,minlat,maxlat=-72,-48,-11,-3 #Amazon definitive box 
# minlon,maxlon,minlat,maxlat=-57.5,-56.5,-17.5,-16.5 # cerrado big box
# minlon,maxlon,minlat,maxlat=-57.25,-57,-17.25,-17 # cerrado cluster 210
# @jit(nopython=True)
###############################################################################
###############################################################################
#Define the file header
aux1 ='year,month,central_lat,central_lon,mean_flux,TPM_flux,CO2_flux,CO_flux,CH4_flux\n'
header = aux1
# # print(header)
outstring=''
outfn = open(outfile, 'w')
outfn.writelines(header) 

###############################################################################
###############################################################################
#Center point and emission coeficient FEER database
# M = get_matrix_lat_lon_feer(minlon-0.25,maxlon-0.5,minlat-0.25,maxlat-0.5)
# M = get_matrix_lat_lon_feer(minlon,maxlon,minlat,maxlat)
# print(M)


###############################################################################
# Initialize S3 file system
fs = s3fs.S3FileSystem(anon=True)

# files = fs.ls('noaa-goes16/ABI-L2-FDCF/2020/'+str(224)+'/'+str(12).zfill(2)+'/')
# with fs.open(files[0], 'rb') as f:
#     ds = xr.open_dataset(BytesIO(f.read()), engine='h5netcdf')

###############################################################################,
#Starting message
print
print('Compiling statistics')
print 

# start = time.time()
rlat,rlon = get_lat_lon(fs)
# end = time.time()
# print(end - start)
# start = time.time()
# Indexes = get_indexes(minlon,maxlon,minlat,maxlat,rlat,rlon,M)
Indexes,M = get_indexes_v3(minlon,maxlon,minlat,maxlat,rlat,rlon,feer_data)
print('Got indexes and matrix')
# print(M)
# end = time.time()
# print(end - start)

ano = 2020


# Criar uma lista com os nomes dos meses
nomes_meses = list(calendar.month_name)[1:]

# Criar uma matriz para armazenar os dados
matriz_meses_dias = []

# Preencher a matriz com os nomes dos meses e os dias julianos correspondentes
dia_juliano = 1
for mes_num in range(1, 13):
    ultimo_dia_mes = calendar.monthrange(ano, mes_num)[1]  # Substitua o ano pelo ano desejado
    dias_julianos = np.arange(dia_juliano, dia_juliano + ultimo_dia_mes)
    
    matriz_meses_dias.append([nomes_meses[mes_num - 1], dias_julianos])
    
    dia_juliano += ultimo_dia_mes

# Converter a matriz para um array do NumPy
matriz_meses_dias = np.array(matriz_meses_dias)

for m in range(7,9):
    #For every define start and end year, days and hours
    start_year,end_year,start_day,end_day,start_hour,end_our = ano,ano,\
    matriz_meses_dias[m,1][0],matriz_meses_dias[m,1][1],15,16
    
    #List the data correspond to the start/end definition
    data_list = get_files(start_year,end_year,start_day,end_day,start_hour,end_our)
    print('Data listed '+str(matriz_meses_dias[m,0]))

    #Process the data and return the variables:
    #year,julian,hhmm,code,central_lat,central_lon,mean_flux,RE_flux
    #CO2_flux,CO_flux,CH4_flux
    
    os.chdir(outdir)
    
    array_lat,array_lon,array_mean_flux,array_mean_TPM,array_CO2_flux,array_CO_flux,array_CH4_flux = process_data_v7(rlat,rlon,data_list,M,Indexes)
    
    lats = np.unique(array_lat)
    lons = np.unique(array_lon)
    lats = lats[::-1]
    
    # print(lats)
    # print(lons)
    
    for k in range(0, len(lats)):
        # print(len(lats))
        for n in range(0, len(lons)):
            index = np.where((array_lat == lats[k]) & (array_lon == lons[n]))
            mean_flux_montly = np.mean(array_mean_flux[index])
            mean_TPM_montly = np.mean(array_mean_TPM[index])
            mean_CO2_montly = np.mean(array_CO2_flux[index])
            mean_C0_montly = np.mean(array_CO_flux[index])
            mean_CH4_montly = np.mean(array_CH4_flux[index])
            outstring = str(ano) +','+ str(matriz_meses_dias[m,0])+','+ str(lats[k])+','+ str(lons[n])+','\
                        +str(mean_flux_montly) +','+ str(mean_TPM_montly)+','+ str(mean_CO2_montly)+','\
                        +str(mean_C0_montly)+','+str(mean_CH4_montly)+ '\n'
            outfn.writelines(outstring)
    # results = str(code) +','+ str(lat)+','+ str(lon)+','+ str(sum_frp)+','+ str(N_frp)+','\
    #     +str(FRE) +','+ str(RE)+','+ str(ME)+','+ str(MCO2)+','+ str(s_sum_me_CO2)+','\
    #     +str(MCO) +','+ str(s_sum_me_CO)+','+ str(MCH4)+','+ str(s_sum_me_CH4)+','\
    #     +str(mean_flux) +','+ str(RE_flux)+','+ str(ME_flux)
    # outstring = str(array_year)+','+ str(array_julian)+','+ str(array_hhmm)+','+ str(array_code)+','\
    #     +str(array_lat) +','+ str(array_lon)+','+ str(array_mean_flux)+','+ str(array_mean_TPM)+','\
    #     +str(array_CO2_flux) +','+ str(array_CO_flux)+','+ str(array_CH4_flux)
    # outfn.writelines(outstring)
    
    # for linha in zip(array_year,array_julian,array_hhmm,array_code,array_lat,array_lon,array_mean_flux,array_mean_TPM,array_CO2_flux,array_CO_flux,array_CH4_flux):
    # outfn.writelines(linha)

#Close the file    
outfn.close()
# print(matriz_meses_dias[3,1][0])
# print(matriz_meses_dias[3,1][-1])
# start_year,end_year,start_day,end_day,start_hour,end_our = 2020,2020,232,233,0,24
# # start = time.time()
# data_list = get_files(start_year,end_year,start_day,end_day,start_hour,end_our)
# print('Data listed')
# # end = time.time()
# # print(end - start)
# # print(data_list[len(data_list)-1])
# # print(len(data_list))

# # start = time.time()
# print('Starting process data')
# process_data_v6(rlat,rlon,data_list,M,Indexes)
# end = time.time()
# print(end - start)
print('Done')


