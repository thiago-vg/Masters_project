# -*- coding: utf-8 -*-
"""
Created on Tue Aug  8 15:14:55 2023

@author: thiag
"""



"""GOES-16 products processing

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tF-GMOUDRPZeFwslQd0fOeL_H1Jtu5mM

Fire product: 

OR_ABI-L2-FDCF-M3_G16_sYYYYJJJHHMMSSs_eYYYYJJJHHMMSSs_cYYYYJJJHHMMSSs.nc
"""

###############################################################################
# Define input and output folders and file
import os
from io import BytesIO
import s3fs
import xarray as xr
# import cartopy.crs as ccrs
import numpy as np
import glob
from pyproj import Proj
import pandas as pd
import warnings
# import time

def get_matrix_lat_lon_feer(minlon,maxlon,minlat,maxlat,dados_feer):
    
    centers_lon = np.linspace(minlon+0.5, maxlon-0.5,num=int(maxlon-minlon))
    centers_lat = np.linspace(minlat+0.5, maxlat-0.5,num=int(maxlat-minlat))
        
    # centers_lon = np.linspace(minlon, maxlon,num=int(maxlon-minlon)+1)
    # print(centers_lon)
    # centers_lat = np.linspace(minlat, maxlat,num=int(maxlat-minlat)+1)
    # print(centers_lat)
    aux_list = []
    
    for i in range(0,len(centers_lat)):
        df2 = dados_feer.loc[(dados_feer['Latitude'] == centers_lat[i]) & (dados_feer['Longitude'] <= maxlon )
                           & (dados_feer['Longitude'] >= minlon ),'Ce_850'].to_numpy()
        aux_list = np.append(aux_list,df2)
        if i == 0:
            aux = np.repeat(centers_lat[i],len(centers_lon))
            lat_lon_feer = np.column_stack((aux,centers_lon))
            # latlon = np.vstack((latlon,au2))
        else:
            # print(i)
            aux = np.repeat(centers_lat[i],len(centers_lon))
            aux2 = np.column_stack((aux,centers_lon))
            lat_lon_feer = np.vstack((lat_lon_feer,aux2))
    # print(lat_lon_feer)
    lat_lon_feer = np.column_stack((lat_lon_feer,aux_list))   
    return lat_lon_feer

###############################################################################
# Initialize geometric variables
def get_lat_lon(file_system):
    files = file_system.ls('noaa-goes16/ABI-L2-FDCF/2021/'+str(200).zfill(3)+'/'+str(15).zfill(2)+'/') # list of 6 files for 2021 day 200, UTC time 15:00, 15:10, 15:20, ..., 15:50

    with fs.open(files[0], 'rb') as f:
      ds0 = xr.open_dataset(BytesIO(f.read()), engine='h5netcdf')

    # sat_h = ds0.goes_imager_projection.perspective_point_height[0] # ubuntu old version
    # sat_lon = ds0.goes_imager_projection.longitude_of_projection_origin[0] # ubuntu old version
    # sat_sweep = ds0.goes_imager_projection.sweep_angle_axis[0] # ubuntu old version
    sat_h = ds0.goes_imager_projection.perspective_point_height # Windows version
    sat_lon = ds0.goes_imager_projection.longitude_of_projection_origin # Windows version
    sat_sweep = ds0.goes_imager_projection.sweep_angle_axis # Windows version
    # oproj=ccrs.Geostationary(central_longitude=sat_lon,satellite_height=sat_h,sweep_axis=sat_sweep)
    p = Proj(proj='geos', h=sat_h, lon_0=sat_lon, sweep=sat_sweep)
    X = np.array(ds0.x) * sat_h
    Y = np.array(ds0.y) * sat_h
    XX, YY = np.meshgrid(X,Y)
    rlon, rlat = p(XX, YY, inverse=True)
    
    return rlat,rlon
# CIMSS product
def get_files(s_year,e_year,s_day,e_day,s_hour,e_our):
    print('Getting file names')
    aux = []
    for y in range(s_year,e_year+1):
        for d in range(s_day,e_day):
            #The range of the variable 'd' will determine the days of the product
            for j in range(s_hour,e_our):
                FD = fs.ls('noaa-goes16/ABI-L2-FDCF/'+str(y)+'/'+str(d).zfill(3)+'/'+str(j).zfill(2)+'/') # list of 6 files for 2020 day 228, UTC time 15:00, 15:10, 15:20, ..., 15:50
                #prodbase='OR_ABI-L2-FDCF-M6_G16_s' #Product code 'OR_ABI-L2-FDCF-M6_G16_s'
                #Difference btw M4 and M6 product?????
                #print("Hello {} {}, hope you're well!".format(first_name,last_name))
                # print('noaa-goes16/ABI-L2-FDCF/2020/'+str(d).zfill(3)+'/'+str(j).zfill(2)+'/')
                # print('Processing day {}, hour: {}'.format(d,str(j).zfill(2))) #Processing Message    
                # print(type(FD))
                # print(np.shape(FD))
                # print(len(FD))
                # print(FD)
                # print(FD[1])
                aux = np.append(aux,FD)
    return aux

def get_indexes(min_lon,max_lon,min_lat,max_lat,rlat,rlon,matrix):
    I = np.where((rlat>=min_lat)&(rlat<=max_lat)&(rlon>=min_lon)&(rlon<=max_lon))
    index_list = []
    index_list.insert(0,I)
    # print(index_list)
    for k in range(0,len(matrix)):
        aux1=np.where((rlat>=matrix[k,0]-0.5)&(rlat<=matrix[k,0]+0.5)&(rlon>=matrix[k,1]-0.5)&(rlon<=matrix[k,1]+0.5))
        index_list.insert(k+1,aux1)
    # print(index_list)
    # print(len(index_list))
    # print(index_list[1])
    return index_list

def get_indexes_v2(min_lon,max_lon,min_lat,max_lat,rlat,rlon):
    centers_lon = np.linspace(minlon+0.25, maxlon-0.25,num=int(maxlon-minlon)*2)
    centers_lat = np.linspace(minlat+0.25, maxlat-0.25,num=int(maxlat-minlat)*2)
    
    
    
    print(centers_lon)
    print(centers_lat)
    
    for i in range(0,len(centers_lat)):
        # df2 = dados_feer.loc[(dados_feer['Latitude'] == centers_lat[i]) & (dados_feer['Longitude'] <= maxlon )
        #                    & (dados_feer['Longitude'] >= minlon ),'Ce_850'].to_numpy()
        # aux_list = np.append(aux_list,df2)
        if i == 0:
            aux = np.repeat(centers_lat[i],len(centers_lon))
            lat_lon_feer = np.column_stack((aux,centers_lon))
            # latlon = np.vstack((latlon,au2))
        else:
            # print(i)
            aux = np.repeat(centers_lat[i],len(centers_lon))
            aux2 = np.column_stack((aux,centers_lon))
            lat_lon_feer = np.vstack((lat_lon_feer,aux2))
    print(lat_lon_feer)
    matrix = lat_lon_feer
    # lat_lon_feer = np.column_stack((lat_lon_feer,aux_list))   
    
    I = np.where((rlat>=min_lat)&(rlat<=max_lat)&(rlon>=min_lon)&(rlon<=max_lon))
    index_list = []
    index_list.insert(0,I)
    print(index_list)
    for k in range(0,len(matrix)):
        aux1=np.where((rlat>=matrix[k,0]-0.25)&(rlat<=matrix[k,0]+0.25)&(rlon>=matrix[k,1]-0.25)&(rlon<=matrix[k,1]+0.25))
        index_list.insert(k+1,aux1)
    # print(index_list)
    # print(len(index_list))
    # print(index_list[1])
    return index_list,matrix

def get_indexes_v3(min_lon,max_lon,min_lat,max_lat,rlat,rlon,dados_feer):
    # minlon,maxlon,minlat,maxlat=-72,-48,-9,-6 #Amazon big box v2
    centers_lon = np.linspace(minlon+0.25, maxlon-0.25,num=int(maxlon-minlon)*2)
    centers_lat = np.linspace(minlat+0.25, maxlat-0.25,num=int(maxlat-minlat)*2)
    
    centers_lon2 = np.linspace(minlon+0.5, maxlon-0.5,num=int(maxlon-minlon))
    centers_lat2 = np.linspace(minlat+0.5, maxlat-0.5,num=int(maxlat-minlat))
    
    # print(centers_lon2)
    # print(centers_lat2)
    aux_list = []
    
    for i in range(0,len(centers_lat2)):
        # df2 = dados_feer.loc[(dados_feer['Latitude'] == centers_lat[i]) & (dados_feer['Longitude'] <= maxlon )
        #                     & (dados_feer['Longitude'] >= minlon ),'Ce_850'].to_numpy()
        df2 = dados_feer.loc[(dados_feer['Latitude'] == centers_lat2[i]) & (dados_feer['Longitude'] <= (maxlon) )
                            & (dados_feer['Longitude'] >= (minlon) ),'Ce_850'].to_numpy()
        aux_list = np.append(aux_list,df2)
        if i == 0:
            aux2 = np.repeat(centers_lat2[i],len(centers_lon2))
            lat_lon_feer2 = np.column_stack((aux2,centers_lon2))
            # latlon = np.vstack((latlon,au2))
        else:
            # print(i)
            aux2 = np.repeat(centers_lat2[i],len(centers_lon2))
            aux2 = np.column_stack((aux2,centers_lon2))
            lat_lon_feer2 = np.vstack((lat_lon_feer2,aux2))
    lat_lon_feer2 = np.column_stack((lat_lon_feer2,aux_list))
    # print(lat_lon_feer2)
    
    for i in range(0,len(centers_lat)):
        # df2 = dados_feer.loc[(dados_feer['Latitude'] == centers_lat[i]) & (dados_feer['Longitude'] <= maxlon )
        #                     & (dados_feer['Longitude'] >= minlon ),'Ce_850'].to_numpy()
        # df2 = dados_feer.loc[(dados_feer['Latitude'] == centers_lat2[i]) & (dados_feer['Longitude'] <= (maxlon-0.50) )
        #                     & (dados_feer['Longitude'] >= (minlon+0.50) ),'Ce_850'].to_numpy()
        # aux_list = np.append(aux_list,df2)
        if i == 0:
            aux = np.repeat(centers_lat[i],len(centers_lon))
            lat_lon_feer = np.column_stack((aux,centers_lon))
            # latlon = np.vstack((latlon,au2))
        else:
            # print(i)
            aux = np.repeat(centers_lat[i],len(centers_lon))
            aux2 = np.column_stack((aux,centers_lon))
            lat_lon_feer = np.vstack((lat_lon_feer,aux2))
    
    # for n in range(0,len(lat_lon_feer)):
    #     dft = dados_feer.loc[((dados_feer['Latitude'] == lat_lon_feer[i,0]-0.25)or(dados_feer['Latitude'] == lat_lon_feer[i,0]+0.25)) 
    #                          & ((dados_feer['Longitude'] == lat_lon_feer[i,1]-0.25 ) or (dados_feer['Longitude'] == lat_lon_feer[i,1]+0.25)),'Ce_850'].to_numpy()
    #     aux_list = np.append(aux_list,dft)
    #     print(aux_list)
    # positions = np.where(latlonfeer[:,0]==)
    teste = []
    for j in range(0, len(lat_lon_feer)):
        for n in range(0,len(lat_lon_feer2)):
            if((lat_lon_feer[j,0]==lat_lon_feer2[n,0]+0.25)or(lat_lon_feer[j,0]==lat_lon_feer2[n,0]-0.25)):
                if((lat_lon_feer[j,1]==lat_lon_feer2[n,1]+0.25)or(lat_lon_feer[j,1]==lat_lon_feer2[n,1]-0.25)):
                    teste = np.append(teste,lat_lon_feer2[n,2])
    # print(lat_lon_feer)
    # print(teste)
    # print(len(lat_lon_feer))
    # print(len(teste))
    # matrix = lat_lon_feer
    lat_lon_feer = np.column_stack((lat_lon_feer,teste))
    matrix = lat_lon_feer
    # print(matrix)
    
    I = np.where((rlat>=min_lat)&(rlat<=max_lat)&(rlon>=min_lon)&(rlon<=max_lon))
    index_list = []
    index_list.insert(0,I)
    # print(index_list)
    for k in range(0,len(matrix)):
        aux1=np.where((rlat>=matrix[k,0]-0.25)&(rlat<=matrix[k,0]+0.25)&(rlon>=matrix[k,1]-0.25)&(rlon<=matrix[k,1]+0.25))
        index_list.insert(k+1,aux1)
    # print(index_list)
    # print(len(index_list))
    # print(index_list[1])
    return index_list,matrix

def process_data_v5(rlat,rlon,files,matrix,indexes):
    # P = np.array(ds.Power) #FRP product
    #####################################################################
    #Transfom the satellite coodinates to lat-lon and selecting the box of interess
    # print(matrix[k,0])

    # caixa = (rlat>=matrix[0,0]-0.5)&(rlat<=matrix[0,0]+0.5)&(rlon>=matrix[0,1]-0.5)&(rlon<=matrix[0,1]+0.5)
    # C_caixa = np.invert(caixa).astype(int)
    os.chdir(outdir)
    for i in range(0,len(files)):
      with fs.open(files[i], 'rb') as f:
          
        ds = xr.open_dataset(BytesIO(f.read()), engine='h5netcdf')
        try:
            #####################################################################
            #Dates and times information of the Data
            #print(files[i].split('/')[5])
            #print(prodbase)
            prodbase = files[i].split('/')[5][:23]
            #print(prodbase)
            starttime=files[i].split(prodbase)[1].split('_')[0]
            #print(starttime)
            year,julian,hhmm=starttime[:4],starttime[4:7],starttime[7:11]
            plottitle=year+','+julian+','+hhmm
            fpart = starttime+','+plottitle
            print('Processing year: {}, day: {}, hour: {}'.format(year,julian,hhmm)) #Processing Message    
            code = int(year) + (int(julian)+(int(hhmm)/100)/24+(int(hhmm) % 100)/60/24)/1000
            code2 = int(year) + (int(julian)+(int(hhmm)/100)/24+(int(hhmm) % 100)/60/24)/365
            #####################################################################
            #FRP Data
            P = np.array(ds.Power)
            # T = np.array(ds.Temp)
            # A = np.array(ds.Area)
            P_box_amazon = P[indexes[1]]
            array_P_box_amazon = P_box_amazon[~np.isnan(P_box_amazon)]
            
            
            # P_box_test = np.ma.masked_array(P,mask=~((rlat>=matrix[0,0]-0.5)&(rlat<=matrix[0,0]+0.5)&(rlon>=matrix[0,1]-0.5)&(rlon<=matrix[0,1]+0.5)))
            # array_P_box_amazon = P_box_test.compressed()[~np.isnan(P_box_test.compressed())]
            # RE = array_P_box_amazon*matrix[0,2]
            # RCO2 = array_P_box_amazon*Ce_CO2*matrix[0,2]
            # RCO = array_P_box_amazon*Ce_CO*matrix[0,2]
            # RCH4 = array_P_box_amazon*Ce_CH4*matrix[0,2]
            # s_RCO2 = array_P_box_amazon*sigma_Ce_CO2*matrix[0,2]
            # s_RCO = array_P_box_amazon*sigma_Ce_CO*matrix[0,2]
            # s_RCH4 = array_P_box_amazon*sigma_Ce_CH4*matrix[0,2]
            
            lat = matrix[0,0]
            lon = matrix[0,1]
            sum_frp = np.sum(array_P_box_amazon)
            N_frp = len(array_P_box_amazon)
            results = str(code) +','+ str(lat)+','+ str(lon)+','+ str(sum_frp)+','+ str(N_frp)
            #Compose results in a string and save them
            outstring = fpart+','+results + '\n'
            outfn.writelines(outstring)
            
            for k in range(1,len(matrix)):
                # print(matrix[k,0])
        
                # caixa = (rlat>=matrix[k,0]-0.5)&(rlat<=matrix[k,0]+0.5)&(rlon>=matrix[k,1]-0.5)&(rlon<=matrix[k,1]+0.5)
                # C_caixa = np.invert(caixa).astype(int)
                P_box_amazon = P[indexes[k+1]]
                array_P_box_amazon = P_box_amazon[~np.isnan(P_box_amazon)]
                # P_box_test = np.ma.masked_array(P,mask=~((rlat>=matrix[k,0]-0.5)&(rlat<=matrix[k,0]+0.5)&(rlon>=matrix[k,1]-0.5)&(rlon<=matrix[k,1]+0.5)))
                # array_P_box_test = P_box_test.compressed()[~np.isnan(P_box_test.compressed())]
                # RE = np.concatenate((RE,array_P_box_amazon*matrix[k,2]))
                # RCO2 = np.concatenate((RCO2,array_P_box_amazon*Ce_CO2*matrix[k,2]))
                # RCO = np.concatenate((RCO,array_P_box_amazon*Ce_CO*matrix[k,2]))
                # RCH4 = np.concatenate((RCH4,array_P_box_amazon*Ce_CH4*matrix[k,2]))
                # s_RCO2 = np.concatenate((s_RCO2,array_P_box_amazon*sigma_Ce_CO2*matrix[k,2]))
                # s_RCO = np.concatenate((s_RCO,array_P_box_amazon*sigma_Ce_CO*matrix[k,2]))
                # s_RCH4 = np.concatenate((s_RCH4,array_P_box_amazon*sigma_Ce_CH4*matrix[k,2]))
                lat = matrix[k,0]
                lon = matrix[k,1]
                
                sum_frp = np.sum(array_P_box_amazon)
                N_frp = len(array_P_box_amazon)
                results = str(code)+','+ str(code2) +','+ str(lat)+','+ str(lon)+','+ str(sum_frp)+','+ str(N_frp)
                #Compose results in a string and save them
                outstring = fpart+','+results + '\n'
                outfn.writelines(outstring)
           
            
           # end = time.time()
            # print(end - start)      
            
            # P_box = P[indexes[0]]
            # array_P_box = P_box[~np.isnan(P_box)]
            # # T_box = T[indexes[0]]
            # # array_T_box = T_box[~np.isnan(T_box)]
            # # A_box = A[indexes[0]]
            # # array_A_box = P_box[~np.isnan(A_box)]
        
            
            # ME = RE*600
            # # print(array_P_box)
            # # print(np.shape(array_P_box))
            # # array_P4_box*Ce2,array_P5_box*Ce2,array_P6_box*Ce2,
            #                         # array_P7_box*Ce2,array_P8_box*Ce2,array_P9_box*Ce2)
            # E_box = array_P_box*600
            # #RE = array_P_box #* Ce
            # #ME = E_box #* Ce
            # MCO2 = RCO2* 600
            # MCO = RCO * 600
            # MCH4 = RCH4 * 600
            # s_MCO2 = (s_RCO2*600)**2
            # s_MCO = (s_RCO*600)**2
            # s_MCH4 = (s_RCH4*600)**2

            # sum_frp = np.sum(array_P_box)
            # # sum_temp = np.sum(array_T_box)
            # # sum_area = np.sum(array_A_box)
            
            # #print(sum_frp)
            # sum_re = np.sum(RE)
            # sum_energy = np.sum(E_box)
            # sum_me = np.sum(ME)
            # sum_me_CO2 = np.sum(MCO2)
            # sum_me_CO = np.sum(MCO)
            # sum_me_CH4 = np.sum(MCH4)
            # s_sum_me_CO2 = np.sqrt(np.sum(s_MCO2))
            # s_sum_me_CO = np.sqrt(np.sum(s_MCO))
            # s_sum_me_CH4 = np.sqrt(np.sum(s_MCH4))
            # #code,Ce(g/MJ),FRP(MW),FRE(MJ),RE(kg/s),ME(kg)
            # results = str(code) +','+ str(sum_frp)+','+ str(sum_temp)+','+ str(sum_area)+','+str(sum_energy) \
            # +','+str(sum_re) +','+str(sum_me) \
            # +','+str(sum_me_CO2) +','+str(s_sum_me_CO2)\
            # +','+str(sum_me_CO) +','+str(s_sum_me_CO)\
            # +','+str(sum_me_CH4) +','+str(s_sum_me_CH4)
               
        
            # #Compose results in a string and save them
            # outstring = fpart+','+results + '\n'
            # outfn.writelines(outstring)
            ###############################################################################

        except OSError as error:
             print(error)
    #Close the file    
    outfn.close()
    return print('Done')

def process_data_v6(rlat,rlon,files,matrix,indexes):
    # P = np.array(ds.Power) #FRP product
    #####################################################################
    #Transfom the satellite coodinates to lat-lon and selecting the box of interess
    # print(matrix[k,0])

    # caixa = (rlat>=matrix[0,0]-0.5)&(rlat<=matrix[0,0]+0.5)&(rlon>=matrix[0,1]-0.5)&(rlon<=matrix[0,1]+0.5)
    # C_caixa = np.invert(caixa).astype(int)
    os.chdir(outdir)
    for i in range(0,len(files)):
      with fs.open(files[i], 'rb') as f:
          
        ds = xr.open_dataset(BytesIO(f.read()), engine='h5netcdf')
        try:
            #####################################################################
            #Dates and times information of the Data
            #print(files[i].split('/')[5])
            #print(prodbase)
            prodbase = files[i].split('/')[5][:23]
            #print(prodbase)
            starttime=files[i].split(prodbase)[1].split('_')[0]
            #print(starttime)
            year,julian,hhmm=starttime[:4],starttime[4:7],starttime[7:11]
            plottitle=year+','+julian+','+hhmm
            fpart = starttime+','+plottitle
            print('Processing year: {}, day: {}, hour: {}'.format(year,julian,hhmm)) #Processing Message    
            # code = int(year) + (int(julian)+(int(hhmm)/100)/24+(int(hhmm) % 100)/60/24)/1000
            code = int(year) + (int(julian)+(int(hhmm)/100)/24+(int(hhmm) % 100)/60/24)/365
            #####################################################################
            #FRP Data
            P = np.array(ds.Power)
            # T = np.array(ds.Temp)
            A = np.array(ds.Area)
            P_box_amazon = P[indexes[1]]
            A_box_amazon = A[indexes[1]]
            # print('Len P_box:', len(P_box_amazon))
            # print('Shape P_box:', np.shape(P_box_amazon))
            # print('Len A_box:', len(A_box_amazon))
            # print('Shape A_box:', np.shape(A_box_amazon))
            
            P_A_box_amazon = P_box_amazon/A_box_amazon
            array_P_box_amazon = P_box_amazon[~np.isnan(P_box_amazon)]
            array_F_box_amazon = P_A_box_amazon[~np.isnan(P_A_box_amazon)]
            
            
            # P_box_test = np.ma.masked_array(P,mask=~((rlat>=matrix[0,0]-0.5)&(rlat<=matrix[0,0]+0.5)&(rlon>=matrix[0,1]-0.5)&(rlon<=matrix[0,1]+0.5)))
            # array_P_box_amazon = P_box_test.compressed()[~np.isnan(P_box_test.compressed())]
            lat = matrix[0,0]
            lon = matrix[0,1]
            sum_frp = np.sum(array_P_box_amazon)
            N_frp = len(array_P_box_amazon)
            FRE = np.sum(array_P_box_amazon*600)
            RE = np.sum(array_P_box_amazon*matrix[0,2])
            ME = np.sum(array_P_box_amazon*matrix[0,2]*600)
            # RCO2 = array_P_box_amazon*Ce_CO2*matrix[0,2]
            # RCO = array_P_box_amazon*Ce_CO*matrix[0,2]
            # RCH4 = array_P_box_amazon*Ce_CH4*matrix[0,2]
            # s_RCO2 = array_P_box_amazon*sigma_Ce_CO2*matrix[0,2]
            # s_RCO = array_P_box_amazon*sigma_Ce_CO*matrix[0,2]
            # s_RCH4 = array_P_box_amazon*sigma_Ce_CH4*matrix[0,2]
            MCO2 = np.sum(array_P_box_amazon*Ce_CO2*matrix[0,2]*600)
            MCO = np.sum(array_P_box_amazon*Ce_CO*matrix[0,2]*600)
            MCH4 = np.sum(array_P_box_amazon*Ce_CH4*matrix[0,2]*600)

            
            s_RCO2 = array_P_box_amazon*sigma_Ce_CO2*matrix[0,2]
            s_RCO = array_P_box_amazon*sigma_Ce_CO*matrix[0,2]
            s_RCH4 = array_P_box_amazon*sigma_Ce_CH4*matrix[0,2]
            s_MCO2 = (s_RCO2*600)**2
            s_MCO = (s_RCO*600)**2
            s_MCH4 = (s_RCH4*600)**2
            s_sum_me_CO2 = np.sqrt(np.sum(s_MCO2))
            s_sum_me_CO = np.sqrt(np.sum(s_MCO))
            s_sum_me_CH4 = np.sqrt(np.sum(s_MCH4))
            
            ###################################################################
            #Método 2 fluxo 
            with warnings.catch_warnings():
                warnings.simplefilter("ignore", category=RuntimeWarning)
                mean_flux = np.mean(array_F_box_amazon)
                RE_flux = np.mean(array_F_box_amazon*matrix[0,2])
                ME_flux = np.mean(array_F_box_amazon*matrix[0,2]*600)
            if np.isnan(mean_flux):
                mean_flux = -9999
            if np.isnan(RE_flux):
                RE_flux = -9999
            if np.isnan(ME_flux):
                ME_flux = -9999
            
            
            
            # aux1 ='sat,year,julian,hhmm,code,central_lat,central_lon,FRP(MW),N_FRP,FRE(MJ),RE(kg/s),ME(kg),
            # CO_2(Kg),sigma_CO_2(Kg),CO(kg),sigma_CO(Kg),CH4(kg),sigma_CH4(Kg)\n'
            # aux1 ='sat,year,julian,hhmm,code,central_lat,central_lon,FRP(MW),N_FRP,FRE(MJ)
            # ,RE(kg/s),ME(kg),CO_2(Kg),sigma_CO_2(Kg),CO(kg),sigma_CO(Kg),CH4(kg),sigma_CH4(Kg)
            # ,mean_flux,RE_flux,ME_flux,\n'



            results = str(code) +','+ str(lat)+','+ str(lon)+','+ str(sum_frp)+','+ str(N_frp)+','\
                +str(FRE) +','+ str(RE)+','+ str(ME)+','+ str(MCO2)+','+ str(s_sum_me_CO2)+','\
                +str(MCO) +','+ str(s_sum_me_CO)+','+ str(MCH4)+','+ str(s_sum_me_CH4)+','\
                +str(mean_flux) +','+ str(RE_flux)+','+ str(ME_flux)
            #Compose results in a string and save them
            outstring = fpart+','+results + '\n'
            outfn.writelines(outstring)
            
            for k in range(1,len(matrix)):
                # print(matrix[k,0])
        
                # caixa = (rlat>=matrix[k,0]-0.5)&(rlat<=matrix[k,0]+0.5)&(rlon>=matrix[k,1]-0.5)&(rlon<=matrix[k,1]+0.5)
                # C_caixa = np.invert(caixa).astype(int)
                P_box_amazon = P[indexes[k+1]]
                array_P_box_amazon = P_box_amazon[~np.isnan(P_box_amazon)]
                
                A_box_amazon = A[indexes[k+1]]
                # print('Len P_box:', len(P_box_amazon))
                # print('Shape P_box:', np.shape(P_box_amazon))
                # print('Len A_box:', len(A_box_amazon))
                # print('Shape A_box:', np.shape(A_box_amazon))
                
                P_A_box_amazon = P_box_amazon/A_box_amazon
                # array_P_box_amazon = P_box_amazon[~np.isnan(P_box_amazon)]
                array_F_box_amazon = P_A_box_amazon[~np.isnan(P_A_box_amazon)]

                
                lat = matrix[k,0]
                lon = matrix[k,1]
                
                sum_frp = np.sum(array_P_box_amazon)
                N_frp = len(array_P_box_amazon)
                
                FRE = np.sum(array_P_box_amazon*600)
                RE = np.sum(array_P_box_amazon*matrix[k,2])
                ME = np.sum(array_P_box_amazon*matrix[k,2]*600)
                # RCO2 = array_P_box_amazon*Ce_CO2*matrix[0,2]
                # RCO = array_P_box_amazon*Ce_CO*matrix[0,2]
                # RCH4 = array_P_box_amazon*Ce_CH4*matrix[0,2]
                # s_RCO2 = array_P_box_amazon*sigma_Ce_CO2*matrix[0,2]
                # s_RCO = array_P_box_amazon*sigma_Ce_CO*matrix[0,2]
                # s_RCH4 = array_P_box_amazon*sigma_Ce_CH4*matrix[0,2]
                MCO2 = np.sum(array_P_box_amazon*Ce_CO2*matrix[k,2]*600)
                MCO = np.sum(array_P_box_amazon*Ce_CO*matrix[k,2]*600)
                MCH4 = np.sum(array_P_box_amazon*Ce_CH4*matrix[k,2]*600)

                
                s_RCO2 = array_P_box_amazon*sigma_Ce_CO2*matrix[k,2]
                s_RCO = array_P_box_amazon*sigma_Ce_CO*matrix[k,2]
                s_RCH4 = array_P_box_amazon*sigma_Ce_CH4*matrix[k,2]
                s_MCO2 = (s_RCO2*600)**2
                s_MCO = (s_RCO*600)**2
                s_MCH4 = (s_RCH4*600)**2
                s_sum_me_CO2 = np.sqrt(np.sum(s_MCO2))
                s_sum_me_CO = np.sqrt(np.sum(s_MCO))
                s_sum_me_CH4 = np.sqrt(np.sum(s_MCH4))
                
                ###################################################################
                with warnings.catch_warnings():
                    warnings.simplefilter("ignore", category=RuntimeWarning)
                    mean_flux = np.mean(array_F_box_amazon)
                    RE_flux = np.mean(array_F_box_amazon*matrix[k,2])
                    ME_flux = np.mean(array_F_box_amazon*matrix[k,2]*600)
                if np.isnan(mean_flux):
                    mean_flux = -9999
                if np.isnan(RE_flux):
                    RE_flux = -9999
                if np.isnan(ME_flux):
                    ME_flux = -9999


                # results = str(code)+','+ str(lat)+','+ str(lon)+','+ str(sum_frp)+','+ str(N_frp)
                results = str(code) +','+ str(lat)+','+ str(lon)+','+ str(sum_frp)+','+ str(N_frp)+','\
                    +str(FRE) +','+ str(RE)+','+ str(ME)+','+ str(MCO2)+','+ str(s_sum_me_CO2)+','\
                    +str(MCO) +','+ str(s_sum_me_CO)+','+ str(MCH4)+','+ str(s_sum_me_CH4)+','\
                    +str(mean_flux) +','+ str(RE_flux)+','+ str(ME_flux)
                #Compose results in a string and save them
                outstring = fpart+','+results + '\n'
                outfn.writelines(outstring)
           

        except OSError as error:
             print(error)
    #Close the file    
    outfn.close()
    return print('Done')
###############################################################################

# Define input and output folders and file
datadir = 'C:/Users/thiag/OneDrive/Documentos/Projeto_Mestrado/Agosto23/emission_graphs/'
# datadir = '/home/thiagovg//Documentos/Projeto_Mestrado/Abril23/FRP_amazon/fire_dinamics_graphs/' # ubuntu old version
# datadir2 = '/home/thiagovg//Documentos/Projeto_Mestrado/Abril23'
datadir2 = 'C:/Users/thiag/OneDrive/Documentos/Projeto_Mestrado/Agosto23'

data = sorted(glob.glob(datadir2+'/FEER*.csv'))
feer_data = pd.read_csv(data[0])
# print(feer_data)

outdir  = datadir+'output/'
# outfile = outdir+'goes_results_box_emission_rate_test_cerrado_cluster_v7.csv'
outfile = outdir+'goes_data_emission_rate_amazon_definitive_box_v9.csv'
###############################################################################

#Define constants

#Acording to Nguyen and Wooster the species emission can be obtained by
#Ce_species = (EF_species/EF_TMP)*Ce_TPM
# EF_CO2 = 1613 # +- 95 g/kg_burned this value is for Savanna and Grassland biome. Andreae, 2001
# s_EF_CO2 = 95
# EF_CO = 65 # +- 20 g/kg_burned this value is for Savanna and Grassland biome. Andreae, 2001
# s_EF_CO = 20
# EF_CH4 = 2.3 # +- 0.9 g/kg_burned this value is for Savanna and Grassland biome. Andreae, 2001
# s_EF_CH4 = 0.9
# EF_TPM = 8.3 # +- 3.2 g/kg_burned this value is for Savanna and Grassland biome. Andreae, 2001
# s_EF_TPM = 3.2

EF_CO2 = 1620 # +- 70 g/kg_burned this value is for Tropical forest biome. Andreae, 2019
s_EF_CO2 = 70
EF_CO = 104 # +- 39 g/kg_burned this value is for Tropical forest biome. Andreae, 2019
s_EF_CO = 39
EF_CH4 = 6.5 # +- 1.6 g/kg_burned this value is for Tropical forest biome. Andreae, 2019
s_EF_CH4 = 1.6
EF_TPM = 8.7 # +- 3.1 g/kg_burned this value is for Tropical forest biome. Andreae, 2019
s_EF_TPM = 3.1

Ce_CO2 = (EF_CO2/EF_TPM) #kg/MJ 
Ce_CO = (EF_CO/EF_TPM)#kg/MJ
Ce_CH4 = (EF_CH4/EF_TPM) #kg/MJ

sigma_Ce_CO2 = np.sqrt((s_EF_CO2/EF_TPM)**2+(EF_CO2*s_EF_TPM/(EF_TPM)**2)**2) 
sigma_Ce_CO = np.sqrt((s_EF_CO/EF_TPM)**2+(EF_CO*s_EF_TPM/(EF_TPM)**2)**2) 
sigma_Ce_CH4 = np.sqrt((s_EF_CH4/EF_TPM)**2+(EF_CH4*s_EF_TPM/(EF_TPM)**2)**2) 
###############################################################################
###############################################################################
# Define a ROI in degrees
#minlon,maxlon,minlat,maxlat=-80,-40,-30,5
#minlon,maxlon,minlat,maxlat=-61,-53,-20,-14
#minlon,maxlon,minlat,maxlat=-58,-56,-18,-16
# minlon,maxlon,minlat,maxlat=-57,-54,-9,-6 #Amazon small box
# minlon,maxlon,minlat,maxlat=-72.5,-48.5,-9.5,-5.5 #Amazon big box
minlon,maxlon,minlat,maxlat=-72,-48,-11,-5 #Amazon big box v2
# minlon,maxlon,minlat,maxlat=-57.5,-56.5,-17.5,-16.5 # cerrado big box
# minlon,maxlon,minlat,maxlat=-57.25,-57,-17.25,-17 # cerrado cluster 210
# @jit(nopython=True)
###############################################################################
###############################################################################
#Define the file header
aux1 ='sat,year,julian,hhmm,code,central_lat,central_lon,FRP(MW),N_FRP,FRE(MJ),RE(kg/s),ME(kg),CO_2(Kg),sigma_CO_2(Kg),CO(kg),sigma_CO(Kg),CH4(kg),sigma_CH4(Kg),mean_flux,RE_flux,ME_flux,\n'
header = aux1
# # print(header)
outstring=''
outfn = open(outfile, 'w')
outfn.writelines(header) 

###############################################################################
###############################################################################
#Center point and emission coeficient FEER database
# M = get_matrix_lat_lon_feer(minlon-0.25,maxlon-0.5,minlat-0.25,maxlat-0.5)
# M = get_matrix_lat_lon_feer(minlon,maxlon,minlat,maxlat)
# print(M)


###############################################################################
# Initialize S3 file system
fs = s3fs.S3FileSystem(anon=True)

# files = fs.ls('noaa-goes16/ABI-L2-FDCF/2020/'+str(224)+'/'+str(12).zfill(2)+'/')
# with fs.open(files[0], 'rb') as f:
#     ds = xr.open_dataset(BytesIO(f.read()), engine='h5netcdf')

###############################################################################,
#Starting message
print
print('Compiling statistics')
print 

# start = time.time()
rlat,rlon = get_lat_lon(fs)
# end = time.time()
# print(end - start)
# start = time.time()
# Indexes = get_indexes(minlon,maxlon,minlat,maxlat,rlat,rlon,M)
Indexes,M = get_indexes_v3(minlon,maxlon,minlat,maxlat,rlat,rlon,feer_data)
print('Got indexes and matrix')
# print(M)
# end = time.time()
# print(end - start)
start_year,end_year,start_day,end_day,start_hour,end_our = 2020,2020,232,233,0,24
# start = time.time()
data_list = get_files(start_year,end_year,start_day,end_day,start_hour,end_our)
print('Data listed')
# end = time.time()
# print(end - start)
# print(data_list[len(data_list)-1])
# print(len(data_list))

# start = time.time()
print('Starting process data')
process_data_v6(rlat,rlon,data_list,M,Indexes)
# end = time.time()
# print(end - start)


