# -*- coding: utf-8 -*-
"""
Created on Thu Jun 29 15:51:16 2023

@author: thiag
"""



"""GOES-16 products processing

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tF-GMOUDRPZeFwslQd0fOeL_H1Jtu5mM

Fire product: 

OR_ABI-L2-FDCF-M3_G16_sYYYYJJJHHMMSSs_eYYYYJJJHHMMSSs_cYYYYJJJHHMMSSs.nc
"""

###############################################################################
# Define input and output folders and file
import os
from io import BytesIO
import s3fs
import xarray as xr
# import cartopy.crs as ccrs
import numpy as np
import glob
from pyproj import Proj
import pandas as pd
# import time

def get_matrix_lat_lon_feer(minlon,maxlon,minlat,maxlat):
    
    centers_lon = np.linspace(minlon+0.5, maxlon-0.5,num=int(maxlon-minlon))
    centers_lat = np.linspace(minlat+0.5, maxlat-0.5,num=int(maxlat-minlat))
        
    # centers_lon = np.linspace(minlon, maxlon,num=int(maxlon-minlon)+1)
    # print(centers_lon)
    # centers_lat = np.linspace(minlat, maxlat,num=int(maxlat-minlat)+1)
    # print(centers_lat)
    aux_list = []
    
    for i in range(0,len(centers_lat)):
        df2 = dados_feer.loc[(dados_feer['Latitude'] == centers_lat[i]) & (dados_feer['Longitude'] <= maxlon )
                           & (dados_feer['Longitude'] >= minlon ),'Ce_850'].to_numpy()
        aux_list = np.append(aux_list,df2)
        if i == 0:
            aux = np.repeat(centers_lat[i],len(centers_lon))
            lat_lon_feer = np.column_stack((aux,centers_lon))
            # latlon = np.vstack((latlon,au2))
        else:
            # print(i)
            aux = np.repeat(centers_lat[i],len(centers_lon))
            aux2 = np.column_stack((aux,centers_lon))
            lat_lon_feer = np.vstack((lat_lon_feer,aux2))
    # print(lat_lon_feer)
    lat_lon_feer = np.column_stack((lat_lon_feer,aux_list))   
    return lat_lon_feer

###############################################################################
# Initialize geometric variables
def get_lat_lon(file_system):
    files = file_system.ls('noaa-goes16/ABI-L2-FDCF/2021/'+str(200).zfill(3)+'/'+str(15).zfill(2)+'/') # list of 6 files for 2021 day 200, UTC time 15:00, 15:10, 15:20, ..., 15:50

    with fs.open(files[0], 'rb') as f:
      ds0 = xr.open_dataset(BytesIO(f.read()), engine='h5netcdf')

    # sat_h = ds0.goes_imager_projection.perspective_point_height[0] # ubuntu old version
    # sat_lon = ds0.goes_imager_projection.longitude_of_projection_origin[0] # ubuntu old version
    # sat_sweep = ds0.goes_imager_projection.sweep_angle_axis[0] # ubuntu old version
    sat_h = ds0.goes_imager_projection.perspective_point_height # Windows version
    sat_lon = ds0.goes_imager_projection.longitude_of_projection_origin # Windows version
    sat_sweep = ds0.goes_imager_projection.sweep_angle_axis # Windows version
    # oproj=ccrs.Geostationary(central_longitude=sat_lon,satellite_height=sat_h,sweep_axis=sat_sweep)
    p = Proj(proj='geos', h=sat_h, lon_0=sat_lon, sweep=sat_sweep)
    X = np.array(ds0.x) * sat_h
    Y = np.array(ds0.y) * sat_h
    XX, YY = np.meshgrid(X,Y)
    rlon, rlat = p(XX, YY, inverse=True)
    
    return rlat,rlon

def get_files(s_year,e_year,s_day,e_day,s_hour,e_our):
    print('Getting file names')
    aux = []
    for y in range(s_year,e_year+1):
        for d in range(s_day,e_day):
            #The range of the variable 'd' will determine the days of the product
            for j in range(s_hour,e_our):
                FD = fs.ls('noaa-goes16/ABI-L2-FDCF/'+str(y)+'/'+str(d).zfill(3)+'/'+str(j).zfill(2)+'/') # list of 6 files for 2020 day 228, UTC time 15:00, 15:10, 15:20, ..., 15:50
                #prodbase='OR_ABI-L2-FDCF-M6_G16_s' #Product code 'OR_ABI-L2-FDCF-M6_G16_s'
                #Difference btw M4 and M6 product?????
                #print("Hello {} {}, hope you're well!".format(first_name,last_name))
                # print('noaa-goes16/ABI-L2-FDCF/2020/'+str(d).zfill(3)+'/'+str(j).zfill(2)+'/')
                # print('Processing day {}, hour: {}'.format(d,str(j).zfill(2))) #Processing Message    
                # print(type(FD))
                # print(np.shape(FD))
                # print(len(FD))
                # print(FD)
                # print(FD[1])
                aux = np.append(aux,FD)
    return aux

def get_indexes(min_lon,max_lon,min_lat,max_lat,rlat,rlon,matrix):
    I = np.where((rlat>=min_lat)&(rlat<=max_lat)&(rlon>=min_lon)&(rlon<=max_lon))
    index_list = []
    index_list.insert(0,I)
    # print(index_list)
    for k in range(0,len(matrix)):
        aux1=np.where((rlat>=matrix[k,0]-0.5)&(rlat<=matrix[k,0]+0.5)&(rlon>=matrix[k,1]-0.5)&(rlon<=matrix[k,1]+0.5))
        index_list.insert(k+1,aux1)
    # print(index_list)
    # print(len(index_list))
    # print(index_list[1])
    return index_list

def get_indexes_v2(min_lon,max_lon,min_lat,max_lat,rlat,rlon):
    centers_lon = np.linspace(minlon+0.25, maxlon-0.25,num=int(maxlon-minlon)*2)
    centers_lat = np.linspace(minlat+0.25, maxlat-0.25,num=int(maxlat-minlat)*2)
    
    print(centers_lon)
    print(centers_lat)
    
    for i in range(0,len(centers_lat)):
        # df2 = dados_feer.loc[(dados_feer['Latitude'] == centers_lat[i]) & (dados_feer['Longitude'] <= maxlon )
        #                    & (dados_feer['Longitude'] >= minlon ),'Ce_850'].to_numpy()
        # aux_list = np.append(aux_list,df2)
        if i == 0:
            aux = np.repeat(centers_lat[i],len(centers_lon))
            lat_lon_feer = np.column_stack((aux,centers_lon))
            # latlon = np.vstack((latlon,au2))
        else:
            # print(i)
            aux = np.repeat(centers_lat[i],len(centers_lon))
            aux2 = np.column_stack((aux,centers_lon))
            lat_lon_feer = np.vstack((lat_lon_feer,aux2))
    print(lat_lon_feer)
    matrix = lat_lon_feer
    # lat_lon_feer = np.column_stack((lat_lon_feer,aux_list))   
    
    I = np.where((rlat>=min_lat)&(rlat<=max_lat)&(rlon>=min_lon)&(rlon<=max_lon))
    index_list = []
    index_list.insert(0,I)
    print(index_list)
    for k in range(0,len(matrix)):
        aux1=np.where((rlat>=matrix[k,0]-0.25)&(rlat<=matrix[k,0]+0.25)&(rlon>=matrix[k,1]-0.25)&(rlon<=matrix[k,1]+0.25))
        index_list.insert(k+1,aux1)
    # print(index_list)
    # print(len(index_list))
    # print(index_list[1])
    return index_list,matrix

def process_data_v5(rlat,rlon,files,matrix,indexes):
    # P = np.array(ds.Power) #FRP product
    #####################################################################
    #Transfom the satellite coodinates to lat-lon and selecting the box of interess
    # print(matrix[k,0])

    # caixa = (rlat>=matrix[0,0]-0.5)&(rlat<=matrix[0,0]+0.5)&(rlon>=matrix[0,1]-0.5)&(rlon<=matrix[0,1]+0.5)
    # C_caixa = np.invert(caixa).astype(int)
    os.chdir(outdir)
    for i in range(0,len(files)):
      with fs.open(files[i], 'rb') as f:
          
        ds = xr.open_dataset(BytesIO(f.read()), engine='h5netcdf')
        try:
            #####################################################################
            #Dates and times information of the Data
            #print(files[i].split('/')[5])
            #print(prodbase)
            prodbase = files[i].split('/')[5][:23]
            #print(prodbase)
            starttime=files[i].split(prodbase)[1].split('_')[0]
            #print(starttime)
            year,julian,hhmm=starttime[:4],starttime[4:7],starttime[7:11]
            plottitle=year+','+julian+','+hhmm
            fpart = starttime+','+plottitle
            print('Processing year: {}, day: {}, hour: {}'.format(year,julian,hhmm)) #Processing Message   
            code = int(julian)+(int(hhmm)/100)/24+(int(hhmm) % 100)/60/24
            # code = int(year) + (int(julian)+(int(hhmm)/100)/24+(int(hhmm) % 100)/60/24)/1000
            # code2 = int(year) + (int(julian)+(int(hhmm)/100)/24+(int(hhmm) % 100)/60/24)/365
            #####################################################################
            #FRP Data
            P = np.array(ds.Power)
            T = np.array(ds.Temp)
            # A = np.array(ds.Area)
            P_box_amazon = P[indexes[1]]
            T_box_amazon = T[indexes[1]]
            array_P_box_amazon = P_box_amazon[~np.isnan(P_box_amazon)]
            array_T_box_amazon = T_box_amazon[~np.isnan(T_box_amazon)]
            # print(type(array_T_box_amazon))
            
        
            
            lat = matrix[0,0]
            lon = matrix[0,1]
            sum_frp = np.sum(array_P_box_amazon)
            mean_temp = np.nanmean(array_T_box_amazon)
            if np.isnan(mean_temp):
                mean_temp = -9999
            N_frp = len(array_P_box_amazon)
            N_temp = len(array_T_box_amazon)
            N_smold = len(array_T_box_amazon[(array_T_box_amazon>500) & (array_T_box_amazon<700)])
            N_flame = len(array_T_box_amazon[(array_T_box_amazon>800) & (array_T_box_amazon<1200)])
            # results = str(code) +','+ str(lat)+','+ str(lon)+','+ str(sum_frp)+','+ str(N_frp)
            # results = str(code)+','+ str(code2) +','+ str(lat)+','+ str(lon)+','+ str(sum_frp)+','+ str(N_frp)
            # aux1 ='sat,year,julian,hhmm,code,central_lat,central_lon,FRP(MW),N_FRP,Temp,N_temp,N_smold,N_flame\n'
            results = str(code) +','+ str(lat)+','+ str(lon)+','+ str(sum_frp)+','+ str(N_frp)+','+ str(mean_temp)+','+ str(N_temp)+','+ str(N_smold)+','+ str(N_flame)
            #Compose results in a string and save them
            outstring = fpart+','+results + '\n'
            outfn.writelines(outstring)
            
            for k in range(1,len(matrix)):
                # print(matrix[k,0])
        
                # caixa = (rlat>=matrix[k,0]-0.5)&(rlat<=matrix[k,0]+0.5)&(rlon>=matrix[k,1]-0.5)&(rlon<=matrix[k,1]+0.5)
                # C_caixa = np.invert(caixa).astype(int)
                P_box_amazon = P[indexes[k+1]]
                array_P_box_amazon = P_box_amazon[~np.isnan(P_box_amazon)]
                T_box_amazon = T[indexes[k+1]]
                array_T_box_amazon = T_box_amazon[~np.isnan(T_box_amazon)]

                lat = matrix[k,0]
                lon = matrix[k,1]
                
                sum_frp = np.sum(array_P_box_amazon)
                mean_temp = np.nanmean(array_T_box_amazon)
                if np.isnan(mean_temp):
                    mean_temp = -9999
                N_frp = len(array_P_box_amazon)
                N_temp = len(array_T_box_amazon)
                N_smold = len(array_T_box_amazon[(array_T_box_amazon>500) & (array_T_box_amazon<700)])
                N_flame = len(array_T_box_amazon[(array_T_box_amazon>800) & (array_T_box_amazon<1200)])
                # results = str(code)+','+ str(code2) +','+ str(lat)+','+ str(lon)+','+ str(sum_frp)+','+ str(N_frp)
                results = str(code) +','+ str(lat)+','+ str(lon)+','+ str(sum_frp)+','+ str(N_frp)+','+ str(mean_temp)+','+ str(N_temp)+','+ str(N_smold)+','+ str(N_flame)
                #Compose results in a string and save them
                outstring = fpart+','+results + '\n'
                outfn.writelines(outstring)
           
            

        except OSError as error:
             print(error)
    #Close the file    
    outfn.close()
    return print('Done')
###############################################################################

# Define input and output folders and file
datadir = 'C:/Users/thiag/OneDrive/Documentos/Projeto_Mestrado/Julho23/fire_dinamics/' #Windows version
# datadir = '/home/thiagovg//Documentos/Projeto_Mestrado/Abril23/FRP_amazon/fire_dinamics_graphs/' # ubuntu old version
datadir2 = 'C:/Users/thiag/OneDrive/Documentos/Projeto_Mestrado/Julho23'


data = sorted(glob.glob(datadir2+'/FEER*.csv'))
dados_feer = pd.read_csv(data[0])

outdir  = datadir+'output/'
# outfile = outdir+'goes_results_box_emission_rate_test_cerrado_cluster_v7.csv'
outfile = outdir+'goes_data_fire_dinamics_amazon_small_box_test_flame_smold.csv'
###############################################################################

#Define constants

#Acording to Nguyen and Wooster the species emission can be obtained by
#Ce_species = (EF_species/EF_TMP)*Ce_TPM
# EF_CO2 = 1613 # +- 95 g/kg_burned this value is for Savanna and Grassland biome. Andreae, 2001
# s_EF_CO2 = 95
# EF_CO = 65 # +- 20 g/kg_burned this value is for Savanna and Grassland biome. Andreae, 2001
# s_EF_CO = 20
# EF_CH4 = 2.3 # +- 0.9 g/kg_burned this value is for Savanna and Grassland biome. Andreae, 2001
# s_EF_CH4 = 0.9
# EF_TPM = 8.3 # +- 3.2 g/kg_burned this value is for Savanna and Grassland biome. Andreae, 2001
# s_EF_TPM = 3.2

EF_CO2 = 1620 # +- 70 g/kg_burned this value is for Tropical forest biome. Andreae, 2019
s_EF_CO2 = 70
EF_CO = 104 # +- 39 g/kg_burned this value is for Tropical forest biome. Andreae, 2019
s_EF_CO = 39
EF_CH4 = 6.5 # +- 1.6 g/kg_burned this value is for Tropical forest biome. Andreae, 2019
s_EF_CH4 = 1.6
EF_TPM = 8.7 # +- 3.1 g/kg_burned this value is for Tropical forest biome. Andreae, 2019
s_EF_TPM = 3.1

Ce_CO2 = (EF_CO2/EF_TPM) #kg/MJ 
Ce_CO = (EF_CO/EF_TPM)#kg/MJ
Ce_CH4 = (EF_CH4/EF_TPM) #kg/MJ

sigma_Ce_CO2 = np.sqrt((s_EF_CO2/EF_TPM)**2+(EF_CO2*s_EF_TPM/(EF_TPM)**2)**2) 
sigma_Ce_CO = np.sqrt((s_EF_CO/EF_TPM)**2+(EF_CO*s_EF_TPM/(EF_TPM)**2)**2) 
sigma_Ce_CH4 = np.sqrt((s_EF_CH4/EF_TPM)**2+(EF_CH4*s_EF_TPM/(EF_TPM)**2)**2) 
###############################################################################
###############################################################################
# Define a ROI in degrees
#minlon,maxlon,minlat,maxlat=-80,-40,-30,5
#minlon,maxlon,minlat,maxlat=-61,-53,-20,-14
#minlon,maxlon,minlat,maxlat=-58,-56,-18,-16
minlon,maxlon,minlat,maxlat=-57,-54,-9,-6 #Amazon small box
# minlon,maxlon,minlat,maxlat=-72.5,-48.5,-9.5,-5.5 #Amazon big box
# minlon,maxlon,minlat,maxlat=-72,-48,-9,-6 #Amazon big box v2
# minlon,maxlon,minlat,maxlat=-57.5,-56.5,-17.5,-16.5 # cerrado big box
# minlon,maxlon,minlat,maxlat=-57.25,-57,-17.25,-17 # cerrado cluster 210
# @jit(nopython=True)
###############################################################################
###############################################################################
#Define the file header
# aux1 ='sat,year,julian,hhmm,code,code2,central_lat,central_lon,FRP(MW),N_FRP,Temp,N_temp,N_smold,N_flame\n'
aux1 ='sat,year,julian,hhmm,code,central_lat,central_lon,FRP(MW),N_FRP,Temp,N_temp,N_smold,N_flame\n'
header = aux1
# # print(header)
outstring=''
outfn = open(outfile, 'w')
outfn.writelines(header) 

###############################################################################
###############################################################################
#Center point and emission coeficient FEER database
# M = get_matrix_lat_lon_feer(minlon-0.25,maxlon-0.5,minlat-0.25,maxlat-0.5)
# M = get_matrix_lat_lon_feer(minlon,maxlon,minlat,maxlat)
# print(M)


###############################################################################
# Initialize S3 file system
fs = s3fs.S3FileSystem(anon=True)

# files = fs.ls('noaa-goes16/ABI-L2-FDCF/2020/'+str(224)+'/'+str(12).zfill(2)+'/')
# with fs.open(files[0], 'rb') as f:
#     ds = xr.open_dataset(BytesIO(f.read()), engine='h5netcdf')

###############################################################################,
#Starting message
print
print('Compiling statistics')
print 

# start = time.time()
rlat,rlon = get_lat_lon(fs)
# end = time.time()
# print(end - start)
# start = time.time()
# Indexes = get_indexes(minlon,maxlon,minlat,maxlat,rlat,rlon,M)
Indexes,M = get_indexes_v2(minlon,maxlon,minlat,maxlat,rlat,rlon)
# end = time.time()
# print(end - start)
start_year,end_year,start_day,end_day,start_hour,end_our = 2020,2020,227,235,0,24
# start = time.time()
data_list = get_files(start_year,end_year,start_day,end_day,start_hour,end_our)
# end = time.time()
# print(end - start)
# print(data_list[len(data_list)-1])
# print(len(data_list))

# start = time.time()
process_data_v5(rlat,rlon,data_list,M,Indexes)
# end = time.time()
# print(end - start)


